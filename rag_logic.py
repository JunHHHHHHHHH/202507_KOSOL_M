# rag_logic.py

import os
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.schema.runnable import RunnablePassthrough
from langchain.schema.output_parser import StrOutputParser

def initialize_rag_chain(openai_api_key, pdf_paths):
    """OpenAI API í‚¤ì™€ PDF íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ RAG ì²´ì¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    print("--- RAG íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì‹œì‘ ---")
    
    all_docs = []
    
    # ëª¨ë“  PDF íŒŒì¼ì„ ìˆœíšŒí•˜ë©° ë¬¸ì„œ ë¡œë“œ
    for i, pdf_path in enumerate(pdf_paths):
        if not os.path.exists(pdf_path):
            raise FileNotFoundError(f"PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")
        
        try:
            loader = PyPDFLoader(pdf_path)
            docs = loader.load()
            
            # ê° ë¬¸ì„œì— íŒŒì¼ ì¸ë±ìŠ¤ ë©”íƒ€ë°ì´í„° ì¶”ê°€
            for doc in docs:
                doc.metadata['file_index'] = i
                doc.metadata['file_name'] = f"Document_{i+1}"
            
            all_docs.extend(docs)
            print(f"âœ… íŒŒì¼ {i+1} ë¡œë“œ ì™„ë£Œ - {len(docs)}í˜ì´ì§€")
            
        except Exception as e:
            print(f"âŒ íŒŒì¼ {i+1} ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            raise e
    
    print(f"âœ… [1/5] ì „ì²´ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ - ì´ {len(all_docs)}í˜ì´ì§€")
   
    # ğŸ”¹ë©”íƒ€ë°ì´í„° ì¶”ê°€ ì½”ë“œ ì‚½ì…
    if file_names:
        current_file_idx = 0
        pages_processed = 0
        
        for i, pdf_path in enumerate(pdf_paths):
            loader = PyPDFLoader(pdf_path)
            docs = loader.load()
            
            # ê° ë¬¸ì„œì— ë©”íƒ€ë°ì´í„° ì¶”ê°€
            for doc in all_docs[pages_processed:pages_processed + len(docs)]:
                doc.metadata['document_id'] = i
                doc.metadata['document_name'] = file_names[i]
                # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (ë³µì¡í•œ extract_topic í•¨ìˆ˜ ëŒ€ì‹ )
                doc.metadata['topic'] = extract_simple_keywords(doc.page_content)
            
            pages_processed += len(docs)
            print(f"ğŸ“‹ ë¬¸ì„œ {i+1} ë©”íƒ€ë°ì´í„° ì¶”ê°€ ì™„ë£Œ: {file_names[i]}")
  
    # ë¬¸ì„œê°€ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸
    if not all_docs:
        raise ValueError("PDF ë¬¸ì„œë“¤ì´ ë¹„ì–´ìˆê±°ë‚˜ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # ë¬¸ì„œ ë‚´ìš© ê¸¸ì´ í™•ì¸
    total_text = ""
    for doc in all_docs:
        total_text += doc.page_content
    
    print(f"ì „ì²´ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(total_text)} ë¬¸ì")
    
    if len(total_text.strip()) < 100:
        raise ValueError("ë¬¸ì„œ ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ìŠ¤ìº”ëœ ì´ë¯¸ì§€ PDFì¼ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.")
    
    try:
        # 2. ë¬¸ì„œ ë¶„í• 
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=500,
            chunk_overlap=50,
            separators=["\n\n", "\n", ".", "!", "?", ",", " ", ""]
        )
        
        splits = text_splitter.split_documents(all_docs)
        print(f"âœ… [2/5] ë¬¸ì„œ ë¶„í•  ì™„ë£Œ - ì´ {len(splits)}ê°œ ì²­í¬")
        
        # ë¶„í•  ê²°ê³¼ í™•ì¸
        if not splits:
            raise ValueError("ë¬¸ì„œ ë¶„í•  ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        
        # ì²« ë²ˆì§¸ ì²­í¬ ë‚´ìš© í™•ì¸
        print(f"ì²« ë²ˆì§¸ ì²­í¬ ë‚´ìš©: {splits[0].page_content[:200]}...")
        
        # 3. OpenAI ì„ë² ë”© ë° ë²¡í„° DB ì„¤ì •
        embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
        vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)
        print("âœ… [3/5] FAISS ë²¡í„° DB ìƒì„± ì™„ë£Œ")
        
        # 4. ê²€ìƒ‰ê¸° ìƒì„±
        retriever = vectorstore.as_retriever(
            search_type="similarity",
            search_kwargs={
                "k": 10,  # ë‹¤ì¤‘ ë¬¸ì„œì´ë¯€ë¡œ ë” ë§ì€ ì²­í¬ ê²€ìƒ‰
                "score_threshold": 0.5  # ìœ ì‚¬ë„ ì„ê³„ê°’ ì„¤ì •
            }
        )
        print("âœ… [4/5] ê²€ìƒ‰ê¸° ìƒì„± ì™„ë£Œ")
        
        # 5. OpenAI LLM ì„¤ì •
        template = """ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ë¬¸ë§¥(context)ì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œë§Œ ì§ˆë¬¸ì— ë‹µí•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

**ì¤‘ìš”í•œ ê·œì¹™:**
1. ì§ˆë¬¸ê³¼ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ì£¼ì œì— ëŒ€í•œ ì •ë³´ë§Œ ë‹µë³€í•˜ì„¸ìš”
2. ë‹¤ë¥¸ ì£¼ì œì˜ ì •ë³´ë¥¼ ì§ˆë¬¸í•œ ì£¼ì œì— ì ìš©í•˜ì§€ ë§ˆì„¸ìš”  
3. ë¬¸ë§¥ì—ì„œ ì§ˆë¬¸í•œ ì£¼ì œì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ë‹¤ë©´ ë°˜ë“œì‹œ "í•´ë‹¹ ë¬¸ì„œë“¤ì—ëŠ” ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤"ë¼ê³  ë‹µë³€í•˜ì„¸ìš”
4. ì—¬ëŸ¬ ë¬¸ì„œì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì€ ê²½ìš°, í†µí•©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”
5. ë‹µë³€ ì‹œ í•´ë‹¹ ì •ë³´ê°€ ì–´ëŠ ë¬¸ì„œì—ì„œ ë‚˜ì˜¨ ê²ƒì¸ì§€ ëª…ì‹œí•˜ì„¸ìš”

ëª¨ë“  ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ëŒ€ë‹µí•´ì£¼ì„¸ìš”.

CONTEXT: {context}

QUESTION: {question}

"""
        
        prompt = ChatPromptTemplate.from_template(template)
        llm = ChatOpenAI(
            model="gpt-3.5-turbo",
            temperature=0,
            openai_api_key=openai_api_key,
            max_tokens=500,
            timeout=30
        )
        
        rag_chain = (
            {"context": retriever, "question": RunnablePassthrough()}
            | prompt
            | llm
            | StrOutputParser()
        )
        
        print("âœ… [5/5] RAG ì²´ì¸ ìƒì„± ì™„ë£Œ")
        
        return rag_chain, retriever
        
    except Exception as e:
        print(f"âŒ RAG ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        raise e

def get_answer(chain, retriever, question):
    """RAG ì²´ì¸ê³¼ ê²€ìƒ‰ê¸°ë¥¼ ì´ìš©í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    # ë””ë²„ê¹…: ê²€ìƒ‰ ê²°ê³¼ í™•ì¸
    try:
        docs = retriever.get_relevant_documents(question)
        print(f"ê²€ìƒ‰ëœ ë¬¸ì„œ ê°œìˆ˜: {len(docs)}")
        for i, doc in enumerate(docs):
            file_info = doc.metadata.get('file_name', 'Unknown')
            print(f"ë¬¸ì„œ {i+1} ({file_info}): {doc.page_content[:200]}...")
    except Exception as e:
        print(f"ê²€ìƒ‰ ë””ë²„ê¹… ì¤‘ ì˜¤ë¥˜: {e}")
    
    return chain.invoke(question)
